# -*- coding: utf-8 -*-
"""Kaggle complete data analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rQAbUrmzI-h4HWHxFHk1SjvBVv2Z3fpx

#<strong><center>Allripe</center></strong> 
#<strong><center>Kaggle Dataset</center></strong>
#<strong><center>Data Analysis</center></strong>

importing essential libraries
"""

import os
import cv2
import numpy as np
from os.path import join
import matplotlib.pyplot as plt
from google.colab import drive
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image 


drive.mount('/content/drive/')

"""plotting an image from train dataset"""

img=image.load_img("/content/drive/My Drive/Allripe/479364_937965_bundle_archive/TRAIN/gala/1_20190917130459_389.png")
plt.imshow(img)

"""reading the size of images"""

cv2.imread("/content/drive/My Drive/Allripe/479364_937965_bundle_archive/TRAIN/gala/1_20190917130459_389.png").shape

"""rescaling train & test images using ImageDataGenerator


"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train = ImageDataGenerator(rescale=1./255)
test = ImageDataGenerator(rescale=1./255)

"""preparing train images"""

train_dataset= train.flow_from_directory('/content/drive/My Drive/Allripe/479364_937965_bundle_archive/TRAIN/',
                                         target_size=(299, 299),
                                         class_mode='categorical')

"""preparing test images"""

test_dataset= test.flow_from_directory('/content/drive/My Drive/Allripe/479364_937965_bundle_archive/TEST/',
                                         target_size=(299, 299),
                                         class_mode='categorical')

"""# **True information of the dataset**

### **Categories of Train & Test Datasets**
"""

train_dataset.class_indices

"""Here, we got 15 classes"""

type(train_dataset.class_indices)

train_dataset.class_indices.keys()

train_dataset.class_indices.values()

"""### 1) Train Dataset"""

print("There are 5658 train images which belong to 15 categories.")

train_dataset.classes

type(train_dataset.classes)

"""checking number of images for every class/category in train dataset"""

import numpy as np

x = train_dataset.classes
unique, counts = np.unique(x, return_counts=True)

print (np.asarray((unique, counts)).T)

type(np.asarray((unique, counts)))

unique

counts

"""presenting actual number of images of each class in train dataset"""

# Build the plot
fig, ax = plt.subplots(figsize=(17, 7))

ax.bar(unique,counts, align='center', alpha=0.5)
ax.set_xlabel('Category',fontsize=30)
ax.set_ylabel('No of Images',fontsize=30)
ax.set_xticks(unique)
ax.set_xticklabels(unique)
ax.set_title('Train Data',fontsize=30)
ax.yaxis.grid(True)


# Save the figure and show
plt.tight_layout()
plt.show()

# Explode out the 'Chemical' pie piece by offsetting it a greater amount
explode = (0.3, 0.25, 0.1, 0.1,0.1, 0.1, 0.1, 0.1,0.4, 0.1, 0.1, 0.1,0.1, 0.1, 0.2)

fig, ax = plt.subplots(figsize=(20, 10))
ax.pie(counts,
       explode=explode,
       labels=unique,
       autopct='%1.1f%%',
       shadow=True,
       startangle=90)
ax.set_xlabel('Category',fontsize=30)
ax.axis('equal')  # Equal aspect ratio ensures the pie chart is circular.
ax.set_title('Train Data',fontsize=30)


plt.show()

"""Hence, maximum number of images belong to `lemon`, followed by `bananas`, & `cucumber_prickly`. That means probability of predicting these 3 images is significantly high.

### 2) Test Dataset
"""

print("There are 135 test images which belong to 15 categories.")

test_dataset.classes

type(test_dataset.classes)

import numpy as np

x = test_dataset.classes
unique, counts = np.unique(x, return_counts=True)

print (np.asarray((unique, counts)).T)

unique

counts

"""presenting actual number of images of each class in test dataset"""

# Build the plot
fig, ax = plt.subplots(figsize=(17, 7))

ax.bar(unique,counts, align='center', alpha=0.5)
ax.set_xlabel('Category',fontsize=30)
ax.set_ylabel('No of Images',fontsize=30)
ax.set_xticks(unique)
ax.set_xticklabels(unique)
ax.set_title('Actual Test Data',fontsize=30)
ax.yaxis.grid(True)


# Save the figure and show
plt.tight_layout()
plt.show()

# Explode out the 'Chemical' pie piece by offsetting it a greater amount
explode = (0.1, 0.1, 0.1, 0.1,0.1, 0.1, 0.1, 0.1,0.1, 0.1, 0.1, 0.1,0.1, 0.1, 0.1)

fig, ax = plt.subplots(figsize=(20, 10))
ax.pie(counts,
       explode=explode,
       labels=unique,
       autopct='%1.1f%%',
       shadow=True,
       startangle=90)
ax.set_xlabel('Category',fontsize=30)
ax.axis('equal')  # Equal aspect ratio ensures the pie chart is circular.
ax.set_title('Actual Test Data',fontsize=30)


plt.show()

"""Hence, all 15 types of images in test dataset are present in equal proportion i.e. 6.7%.

# **Predicted information of the dataset**

### Least Probability of predicting an image correctly
"""

round(1/15*100,1)

"""Keras Model Building using a Pretrained Model (Transfer Learning) i.e. `InceptionV3`"""

from keras.models import Model 
from keras.layers import Dropout, Dense, BatchNormalization
from keras.applications.inception_v3 import InceptionV3




def build_model(num_features):
  base = InceptionV3(input_shape=(299, 299, 3),
                     weights='imagenet',
                     include_top=True
                     ) 
  
  # model top
  #x = base.output
  x= base.layers[-2].output
  #x = Dense(120, activation='relu')(x)
  #x = BatchNormalization()(x)
  #x = Dropout(0.45)(x)
  top = Dense(15, activation='softmax')(x)
  
  return Model(inputs=base.input, outputs=top)

"""finalizing the model and creating a summary of it. """

model = build_model(num_features=299)
model.summary()

"""

We are doing multiple categorization, so categorical_crossentropy is still the right loss function to use. We'll use the Adam optimizer."""

# make all layers untrainable by freezing weights (except for last layer)
'''for l, layer in enumerate(model.layers[:-1]):
    layer.trainable = False'''

import tensorflow 
from tensorflow import keras
from keras.layers import Dense
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
model.compile(loss="categorical_crossentropy", optimizer=keras.optimizers.Adam(learning_rate=0.0003),metrics=["accuracy"])

"""And now we train our model"""

history=model.fit(train_dataset,epochs = 10, validation_data= (test_dataset))

"""Let's plot the validation loss and validation accuracy over time."""

fig = plt.figure(figsize=(16,4))
ax = fig.add_subplot(121)
ax.plot(history.history["val_loss"])
ax.set_title("test loss")
ax.set_xlabel("epochs")

ax2 = fig.add_subplot(122)
ax2.plot(history.history["val_accuracy"])
ax2.set_title("test accuracy")
ax2.set_xlabel("epochs")
ax2.set_ylim(0, 1)

plt.show()

"""Above we achieved top-5 accuracy of 86%.
Now, we'll predict `test images`
"""

y_prob = model.predict(test_dataset)
y_prob

y_pred = np.argmax(y_prob,axis=1)
y_pred

"""`y_pred` is the predicted values of test dataset images."""

import numpy as np

x = y_pred
unique, counts = np.unique(x, return_counts=True)

print (np.asarray((unique, counts)).T)

unique

counts

# Build the plot
fig, ax = plt.subplots(figsize=(17, 7))

ax.bar(unique,counts, align='center', alpha=0.5)
ax.set_xlabel('Category',fontsize=30)
ax.set_ylabel('No of Images',fontsize=30)
ax.set_xticks(unique)
ax.set_xticklabels(unique)
ax.set_title('Predicted Test Data',fontsize=30)
ax.yaxis.grid(True)


# Save the figure and show
plt.tight_layout()
plt.show()

"""So, most of the images are predicted as `grapefruit_yellow` & `sultana`. However, no image is predicted as `lady_fingers`."""

# Explode out the 'Chemical' pie piece by offsetting it a greater amount
explode = (0.4, 0.1, 0.1, 0.4,0.1, 0.4, 0.1, 0.4,0.1, 0.1, 0.1, 0.4,0.1, 0.1)

fig, ax = plt.subplots(figsize=(20, 10))
ax.pie(counts,
       explode=explode,
       labels=unique,
       autopct='%1.1f%%',
       shadow=True,
       startangle=90)
ax.set_xlabel('Category',fontsize=30)
ax.axis('equal')  # Equal aspect ratio ensures the pie chart is circular.
ax.set_title('Predicted Test Data',fontsize=30)


plt.show()

"""* Therefore, `gala`, `golden`, `granny_smith`, `mandarin`, `orange`, `pepper_red`, & `tomato_plum` are predicted exactly in the same proportion as they were present in actual `test dataset`. 

* The actual proportion of every image class was `6.7%`. 

* Classes `grapefruit_yellow`, `sultana`, `cucumber_prickly`, & `bananas` are predicted in a much more proportion then their actual proportion (6.7%). 

* However, `grape_black`, `lemon`, & `pepper_yellow` are predicted in comparatively less proportion as per the actual proportion of every class i.e. 6.7%. 

* Not even a single image is predicted as `lady_fingers`.

## **Conclusion**
It's really hard to predict `lady_fingers`, `lemon`, & `grape_black` correctly.
"""